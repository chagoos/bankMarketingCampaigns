{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set pandas display options for better visibility\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank-additional-full.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  duration  campaign  pdays  previous     poutcome  \\\n",
       "0   may         mon       261         1    999         0  nonexistent   \n",
       "1   may         mon       149         1    999         0  nonexistent   \n",
       "2   may         mon       226         1    999         0  nonexistent   \n",
       "3   may         mon       151         1    999         0  nonexistent   \n",
       "4   may         mon       307         1    999         0  nonexistent   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "1           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "2           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "3           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "4           1.1          93.994          -36.4      4.857       5191.0  no  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Dataset Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n",
      "None\n",
      "Shape of dataset: (41188, 21)\n",
      "Missing Values per Feature:\n",
      "age               0\n",
      "job               0\n",
      "marital           0\n",
      "education         0\n",
      "default           0\n",
      "housing           0\n",
      "loan              0\n",
      "contact           0\n",
      "month             0\n",
      "day_of_week       0\n",
      "duration          0\n",
      "campaign          0\n",
      "pdays             0\n",
      "previous          0\n",
      "poutcome          0\n",
      "emp.var.rate      0\n",
      "cons.price.idx    0\n",
      "cons.conf.idx     0\n",
      "euribor3m         0\n",
      "nr.employed       0\n",
      "y                 0\n",
      "dtype: int64\n",
      "Unique values per feature:\n",
      "age: 78 unique values\n",
      "job: 12 unique values\n",
      "marital: 4 unique values\n",
      "education: 8 unique values\n",
      "default: 3 unique values\n",
      "housing: 3 unique values\n",
      "loan: 3 unique values\n",
      "contact: 2 unique values\n",
      "month: 10 unique values\n",
      "day_of_week: 5 unique values\n",
      "duration: 1544 unique values\n",
      "campaign: 42 unique values\n",
      "pdays: 27 unique values\n",
      "previous: 8 unique values\n",
      "poutcome: 3 unique values\n",
      "emp.var.rate: 10 unique values\n",
      "cons.price.idx: 26 unique values\n",
      "cons.conf.idx: 26 unique values\n",
      "euribor3m: 316 unique values\n",
      "nr.employed: 11 unique values\n",
      "y: 2 unique values\n",
      "Data Types:\n",
      "age                 int64\n",
      "job                object\n",
      "marital            object\n",
      "education          object\n",
      "default            object\n",
      "housing            object\n",
      "loan               object\n",
      "contact            object\n",
      "month              object\n",
      "day_of_week        object\n",
      "duration            int64\n",
      "campaign            int64\n",
      "pdays               int64\n",
      "previous            int64\n",
      "poutcome           object\n",
      "emp.var.rate      float64\n",
      "cons.price.idx    float64\n",
      "cons.conf.idx     float64\n",
      "euribor3m         float64\n",
      "nr.employed       float64\n",
      "y                  object\n",
      "dtype: object\n",
      " 'Unknown' value counts (indicating missing categorical data):\n",
      "job           330\n",
      "marital        80\n",
      "education    1731\n",
      "default      8597\n",
      "housing       990\n",
      "loan          990\n",
      "dtype: int64\n",
      "- All numeric columns are already in numeric format (int64/float64).\n",
      "- Categorical variables are of type 'object' and will need encoding.\n",
      "- 'unknown' entries should be treated as missing values during preprocessing.\n",
      "- The 'duration' feature will be removed before modeling to avoid target leakage.\n"
     ]
    }
   ],
   "source": [
    "# Display basic info about the dataset\n",
    "print(\"üîç Dataset Overview:\")\n",
    "print(df.info())\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing Values per Feature:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check unique values for each column to understand categorical levels\n",
    "print(\"Unique values per feature:\")\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].nunique()} unique values\")\n",
    "\n",
    "# Check data types\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Identify potential features needing coercion or cleanup\n",
    "# Note: The dataset uses 'unknown' instead of NaN for missing categorical values.\n",
    "unknown_counts = (df == 'unknown').sum()\n",
    "print(\" 'Unknown' value counts (indicating missing categorical data):\")\n",
    "print(unknown_counts[unknown_counts > 0])\n",
    "\n",
    "# Recommendations\n",
    "print(\"- All numeric columns are already in numeric format (int64/float64).\")\n",
    "print(\"- Categorical variables are of type 'object' and will need encoding.\")\n",
    "print(\"- 'unknown' entries should be treated as missing values during preprocessing.\")\n",
    "print(\"- The 'duration' feature will be removed before modeling to avoid target leakage.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (3142216578.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[53], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    The business objective is to increase the efficiency and success rate of the bank's direct marketing phone campaigns for term deposit subscription.\u001b[0m\n\u001b[1;37m                                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "The business objective is to increase the efficiency and success rate of the bank's direct marketing phone campaigns for term deposit subscription. \n",
    "This is achieved by building a predictive model that can accurately identify and prioritize potential clients who are most likely to subscribe to a term deposit (target variable y='yes') before the campaign call is made. \n",
    "By focusing resources (time, money, human effort) on these high-potential clients, the bank can maximize its return on investment and minimize wasted contacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features, prepare the features and target column for modeling with appropriate encoding and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e will build a basic model to get started. Before we can do this, we must work to encode the data. Using just the bank information features (age, job, marital, education, default, housing, loan), prepare the features and target column for modeling with appropriate encoding and transformations.\n",
    "\n",
    "Steps:\n",
    "\n",
    "Select features and target.\n",
    "\n",
    "Encode the target variable y.\n",
    "\n",
    "Apply One-Hot Encoding to categorical features.\n",
    "\n",
    "Apply StandardScaler to the numeric feature (age)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Select only the bank client data features\n",
    "BANK_CLIENT_FEATURES = ['age', 'job', 'marital', 'education', 'default', 'housing', 'loan']\n",
    "TARGET = 'y'\n",
    "\n",
    "df_model = df[BANK_CLIENT_FEATURES + [TARGET]].copy()\n",
    "\n",
    "# 2. Encode the target variable 'y'\n",
    "# 'yes' = 1 (Subscribed), 'no' = 0 (Did not subscribe)\n",
    "df_model[TARGET] = df_model[TARGET].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# 3. Apply One-Hot Encoding to categorical features\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan']\n",
    "df_model = pd.get_dummies(df_model, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Define the feature matrix X and target vector y\n",
    "X = df_model.drop(TARGET, axis=1)\n",
    "y = df_model[TARGET]\n",
    "\n",
    "# 4. Identify and scale the numeric feature 'age'\n",
    "numeric_features = ['age']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform 'age'\n",
    "X['age'] = scaler.fit_transform(X[['age']])\n",
    "\n",
    "# Check for any remaining non-numeric columns (should be empty)\n",
    "object_cols_check = X.select_dtypes(include='object').columns.tolist()\n",
    "if object_cols_check:\n",
    "    # This warning is added to help diagnose the issue that caused the ValueError\n",
    "    print(f\"Warning: Non-numeric columns found before split: {object_cols_check}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Train/Test Split\n",
    "\n",
    "With your data prepared, split it into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "With the engineered features, perform a train/test split. Use 80% of the data for training and 20% for testing. Set random_state=42 for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (32950, 28)\n",
      "X_test shape: (8238, 28)\n"
     ]
    }
   ],
   "source": [
    "# Perform the 80/20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Value Counts:\n",
      "y_encoded\n",
      "0    36548\n",
      "1     4640\n",
      "Name: count, dtype: int64\n",
      "Total Observations: 41188\n",
      "Baseline Accuracy (Majority Class Proportion): 0.8873\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('bank-additional-full.csv', sep = ';')\n",
    "\n",
    "# Encode the target variable 'y'\n",
    "# 'no' -> 0, 'yes' -> 1\n",
    "df['y_encoded'] = df['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Calculate the value counts and total number of observations\n",
    "target_counts = df['y_encoded'].value_counts()\n",
    "total_observations = len(df)\n",
    "\n",
    "# Determine the majority class and its proportion (baseline accuracy)\n",
    "majority_class_count = target_counts.max()\n",
    "baseline_accuracy = majority_class_count / total_observations\n",
    "\n",
    "print(f\"Target Value Counts:\\n{target_counts}\")\n",
    "print(f\"Total Observations: {total_observations}\")\n",
    "print(f\"Baseline Accuracy (Majority Class Proportion): {baseline_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: A Simple Model\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Fit the model to the training data\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_initial = log_reg_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Score the Model\n",
    "\n",
    "What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy : 0.8874\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_accuracy = accuracy_score(y_test, y_pred_initial)\n",
    "\n",
    "print(f\"Logistic Regression Test Accuracy : {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Model Comparisons\n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
    "\n",
    "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "| ----- | ---------- | -------------  | -----------   |\n",
    "|     |    |.     |.     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Comparison Results ---\n",
      "Training Logistic Regression...\n",
      "Training K Nearest Neighbors...\n",
      "Training Decision Tree...\n",
      "Training Support Vector Machine (SVC)...\n",
      "\n",
      "Classification Model Performance Comparison (Full Features):\n",
      "                          Model Train Time (s) Train Accuracy Test Accuracy\n",
      "0           Logistic Regression         0.1499         0.8873        0.8874\n",
      "1           K Nearest Neighbors         0.0212         0.8917        0.8809\n",
      "2                 Decision Tree         0.1403         0.9171        0.8640\n",
      "3  Support Vector Machine (SVC)       110.0057         0.8883        0.8865\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "    \"K Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Support Vector Machine (SVC)\": SVC(random_state=42)\n",
    "}\n",
    "\n",
    "results = defaultdict(list)\n",
    "\n",
    "print(\"--- Model Comparison Results ---\")\n",
    "\n",
    "# Train, time, and score each model\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    fit_time = time.time() - start_time\n",
    "\n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Scoring\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    # Store results\n",
    "    results[\"Model\"].append(name)\n",
    "    results[\"Train Time (s)\"].append(f\"{fit_time:.4f}\")\n",
    "    results[\"Train Accuracy\"].append(f\"{train_accuracy:.4f}\")\n",
    "    results[\"Test Accuracy\"].append(f\"{test_accuracy:.4f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Classification Model Performance Comparison \")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11: Improving the Model\n",
    "\n",
    "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
    "\n",
    "\n",
    "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
    "- Adjust your performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Problem 10: Starting GridSearchCV for Decision Tree (Optimizing for ROC AUC) ---\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Decision Tree Model Parameters:\n",
      "{'max_depth': 9, 'min_samples_leaf': 40, 'min_samples_split': 10}\n",
      "\n",
      "--- Problem 11: Final Evaluation (Best Tuned Decision Tree) ---\n",
      "\n",
      "Classification Report (Best DT Model on Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      No (0)       0.89      1.00      0.94      7310\n",
      "     Yes (1)       0.45      0.03      0.05       928\n",
      "\n",
      "    accuracy                           0.89      8238\n",
      "   macro avg       0.67      0.51      0.50      8238\n",
      "weighted avg       0.84      0.89      0.84      8238\n",
      "\n",
      "\n",
      "Confusion Matrix (Best DT Model on Test Set):\n",
      " [[7278   32]\n",
      " [ 902   26]]\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [5, 7, 9, 11],\n",
    "    'min_samples_leaf': [20, 30, 40],\n",
    "    'min_samples_split': [10, 20, 30],\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV, optimizing for ROC AUC\n",
    "print(\"\\n--- Problem 10: Starting GridSearchCV for Decision Tree (Optimizing for ROC AUC) ---\")\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=dt_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',  # Best metric for imbalanced data\n",
    "    cv=5,               # 5-fold cross-validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best Decision Tree Model Parameters:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Use the best model to predict on the test set\n",
    "y_pred_best = best_dt_model.predict(X_test)\n",
    "\n",
    "# Generate Classification Report and Confusion Matrix\n",
    "report = classification_report(y_test, y_pred_best, target_names=['No (0)', 'Yes (1)'])\n",
    "matrix = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "\n",
    "print(\"Classification Report of Best Decision Tree Model on Test Set\")\n",
    "print(report)\n",
    "print(\"Confusion Matrix of Best DT Model on Test Set\", matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
